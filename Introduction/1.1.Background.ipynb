{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1. Background**\n",
        "\n",
        "In this section, let's start by discussing the background of the two different disciplines we defined earlier. Rather than focusing on theory, let's explore a bit of the historical process. For instance, let's discuss how we merged these two disciplines, how Quantum Machine Learning became a popular area of research over time, and examine the approaches in this field.\n",
        "\n",
        "Firstly, let's discuss how we combined or merged these two different fields or disciplines."
      ],
      "metadata": {
        "id": "KR_9G0Xcybcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.1. Merging the Two Disciplines**\n",
        "\n",
        "Computers are physical devices based on electronic circuits that process information. Algorithms, also referred to as computer programs or software, describe how we manipulate the information represented by currents in these circuits and are used to perform computations. Although the physical processes involved in these operations include particles such as electrons, atoms, and molecules, we can express these processes using classical features of electronic circuits for all practical purposes. However, when microscopic systems such as photons, electrons, and atoms are directly used for information processing, we need a mathematical description that differs significantly from the intuitive understanding we are taught. This required mathematical framework is called **quantum theory** and is expressed as the most comprehensive physics description at the microscopic scale. A computer that can be defined by the laws of quantum theory is called a **quantum computer**.\n",
        "\n",
        "Unlike traditional computers, which perform computations based on the principles of classical physics, we said that quantum computers perform computations based on the principles of quantum mechanics. Special languages have been developed to describe the computations performed by these computers, helping us understand the behaviors of quantum systems.\n",
        "\n",
        "We can say that the most famous language for quantum computation is the circuit model. This model is used to understand computations in quantum computers. Essentially, it uses concepts such as quantum bits or qubits instead of bits in traditional computers, and quantum gates that operate on these qubits. Thus, quantum algorithms can be developed and executed on quantum computers.\n",
        "\n",
        "The development of quantum computers is a challenging process because these systems require precise control of microscopic particles. Additionally, it is crucial to preserve the fragile nature of these particles; otherwise, the desired quantum effects may disappear. Therefore, error correction in quantum computers is highly critical but is a much more challenging process than in classical systems. The realization of quantum computers requires an international, interdisciplinary, and commercial effort. In this process, prototypes like Noisy Intermediate-Scale Quantum (NISQ) devices have been developed. These devices still operate without error correction and have a limited number of qubits. However, they can be used to demonstrate some advantages of quantum computation. Nevertheless, working with a limited number of qubits and gates in the early stages of quantum computers deeply affects the design of quantum algorithms. Therefore, there is an ongoing race to discover certain algorithms, especially called \"killer applications,\" which can be used with small-scale quantum devices to solve specific problems.\n",
        "\n",
        "The development of quantum computers is closely related to fields such as machine learning. Machine learning uses computer algorithms to extract patterns from large and complex datasets. This can be used for tasks such as image recognition or natural language processing. Machine learning can also play a significant role in the development of quantum computers, as quantum computations offer potential for solving some complex problems.\n",
        "\n",
        "Machine learning is a large research discipline with broad industrial applications. Especially, neural network-based algorithms called deep learning are trained with large datasets using high-performance computing systems. However, success in this field is not solely based on practical applications; it also involves a theoretical background.\n",
        "\n",
        "The emergence of deep learning brought forth a challenging problem that needed to be deeply understood in the field of machine learning: understanding why deep learning works exactly. Traditional learning theory argued that there was a balance between the complexity of a model and its ability to learn. However, modern neural network models challenge this balance due to having millions or billions of trainable parameters. In this case, heavily parameterized models might overfit the training data, which can be concerning.\n",
        "\n",
        "In recent years, efforts to develop theories in machine learning have increased. However, many questions still await answers. Research shows that a good machine learning method consists of a complex interaction of data, model, and optimization algorithm. These developments place the field of machine learning on an exciting but sometimes complex ground. Quantum machine learning adds a new dimension to this dynamic field. Advancing in this area offers both exciting opportunities and requires navigating on challenging terrain."
      ],
      "metadata": {
        "id": "hOF_LuegyjvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.2. The Rise of Quantum Machine Learning**\n",
        "\n",
        "Since the emergence of Quantum Computers, many proposals combining quantum computation and machine learning have been put forward by researchers. The initial contributions focused on quantum models of *neural networks*. These models typically aim to use quantum theory to explain the functioning of the brain, often inspired by biological systems. Subsequently, discussions were held on statistical learning theory in the quantum environment, but this topic did not receive much attention.\n",
        "\n",
        "The term Quantum Machine Learning only started to be widely used relatively recently. In particular, the book \"Quantum Machine Learning--What quantum computing means to data mining\" published by Peter Wittek in 2014 played a significant role in this field. Today, Quantum Machine Learning has established itself as an active subfield of quantum computation research and has various subdomains."
      ],
      "metadata": {
        "id": "W6EfKGhAysOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1.3. Fault-Tolerant and Near-Term Approaches**\n",
        "\n",
        "Quantum machine learning distinguishes between fault-tolerant and near-term approaches. The fault-tolerant approach aims to find quantum algorithms that can produce the exact results of classical machine learning algorithms faster. This typically focuses on the concept of \"faster\" derived from complexity theory. For example, in cases where the quantum algorithm grows linearly with the size of the dataset while the classical algorithm grows quadratically, it can be said that the quantum algorithm is \"quadratically faster than its classical counterpart.\" However, these claims often come with assumptions about data access or detailed explanations and their practical utility is questioned.\n",
        "\n",
        "The fault-tolerant approach usually relies on a fully error-corrected quantum computer, which is not possible in the NISQ era. This approach plays into a long-term vision and dominates quantum machine learning research. However, with the increasing prevalence of NISQ devices, a new approach based on the constraints of small-scale quantum devices has emerged. This \"second wave\" of quantum machine learning is an approach that explores quantum devices not only for accelerating computations but also for using them as a machine learning model.\n",
        "\n",
        "The near-term approach aims to develop machine learning models tailored to the physical properties of specific quantum devices. These new models and training algorithms are derived from the quantum computing paradigm and often rely on classical machine learning theory and practical knowledge. However, a challenge of this approach is how to quantify the performance of a quantum machine learning model. Standard datasets and benchmark tests common in classical machine learning may be insufficient to provide insights into real-world usage of quantum models.\n",
        "\n",
        "To address these challenges, a \"third wave\" of quantum machine learning approach is emerging. This approach attempts to understand the characteristics of new quantum models using both classical machine learning and quantum information theory tools. These theoretical studies may be crucial for understanding the contribution of quantum to quantum machine learning problems. However, more work is needed in this area as both positive and negative results are required to determine how effective quantum machine learning algorithms are in practical use."
      ],
      "metadata": {
        "id": "fD5xBALny2N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sure, here are some brief notes:**\n",
        "\n",
        "1. The research style in fault-tolerant quantum computation approach is derived from the questions posed by the quantum computation community, the methods developed, and the desired outcomes. The main objective here is to find quantum algorithms that could potentially accelerate machine learning algorithms. In other words, they are expected to produce the exact result of a classical routine, but in a faster manner. The definition of \"faster\" is derived from complexity theory, and it typically refers to the slower growth in worst-case runtime with the asymptotic growth of problem size.\n",
        "\n",
        "2. Usually, algorithms arising from the fault-tolerant approach require a fully error-corrected quantum computer, which is prohibitive for the current era. This more traditional approach, therefore, plays into the long-term vision of quantum computation and dominates early quantum machine learning research – we can refer to this as the \"first wave\" of quantum machine learning.\n",
        "\n",
        "3. The near-term approach of quantum machine learning typically starts with a specific constrained quantum device and asks which type of machine learning model could be suitable for its physical characteristics. This leads to entirely new models and training algorithms, derived from a quantum computing paradigm. For this, there is a need for a solid understanding of the intricacies of machine learning and, particularly, the practical performance of the new model."
      ],
      "metadata": {
        "id": "Ps78BEy_y5mh"
      }
    }
  ]
}